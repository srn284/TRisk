{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.insert(0,'/gpfs3/well/rahimi/users/gra027/JNb/')\n",
    "concordance = []\n",
    "brier = []\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import HORIZON.CVmortalityPred_inHF. pytorch_pretrained_bert as Bert\n",
    "from HORIZON.CVmortalityPred_inHF. pytorch_pretrained_bert import optimizer\n",
    "import sklearn.metrics as skm\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.utils import *\n",
    "\n",
    "sys.path.insert(0, '/gpfs3/well/rahimi/users/gra027/JNb/HORIZON/CVmortalityPred_inHF/ModelPkg/')\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.BEHRTsurv import *\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.Data_Deterministic import *\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.utils import *\n",
    "import matplotlib as plt\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.BEHRTSodenXcal import *\n",
    "\n",
    "from torch import optim as toptimizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.TriSched import *\n",
    "\n",
    "from HORIZON.CVmortalityPred_inHF.ModelPkg.CPHloss import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_params = {\n",
    "    'batch_size': 64,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'num_train_epochs': 3,\n",
    "    'device': 'cuda:0',\n",
    "    'output_dir': \"SavedModels/\",\n",
    "    'save_model': True,\n",
    "    'max_len_seq': 512,\n",
    "    'max_age': 110,\n",
    "    'age_year': False,\n",
    "    'age_symbol': None,\n",
    "    'fac': 2.0,\n",
    "    'maxfac': 2.0,\n",
    "    'diseaseI': 1,\n",
    "    'treatments': 2,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (example, label, length)\n",
    "             where 'example' is a tensor of arbitrary shape\n",
    "             and label/length are scalars\n",
    "    \"\"\"\n",
    "    newb = []\n",
    "    for x in zip(*batch):\n",
    "        newb.append(np.array([np.array(elem) for elem in x]))\n",
    "    newbatch = []\n",
    "    idx = np.argsort(newb[-3].flatten())\n",
    "    row = np.arange(len(batch))\n",
    "    for  i , x in enumerate(newb):\n",
    "        temp = x[idx]\n",
    "        newbatch.append(temp)\n",
    "        \n",
    "    age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat  = newbatch\n",
    "    return torch.LongTensor(age_ids), torch.LongTensor(input_ids), torch.LongTensor(posi_ids), torch.LongTensor(segment_ids), \\\n",
    "               torch.LongTensor(attMask), torch.FloatTensor(time2event), torch.LongTensor( label),torch.FloatTensor( labelfloat)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop(e, binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "        dataset_train = SODENXcal_DataLoader(BertVocab['token2idx'], train, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "    else:\n",
    "        dataset_train = SODENXcal_DataLoader(BertVocab['token2idx'], train, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "\n",
    "    dl_train = DataLoader(dataset_train, global_params['batch_size'], shuffle=True, collate_fn = collate_fn)\n",
    "\n",
    "\n",
    "    \n",
    "    z_means = []\n",
    "    z_std = []\n",
    "    model.train()\n",
    "    model.binary=binaryFlag\n",
    "    tr_loss = 0\n",
    "    temp_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    cnt = 0\n",
    "    temp_lossxcal = 0\n",
    "    scale2add = ((global_params['maxfac']- global_params['fac']) )/(len(dl_train) * (5/6))\n",
    "    for step, batch in enumerate(dl_train):\n",
    "        cnt += 1\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        logits , outfull,loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label, labelfloat, time2event)\n",
    "\n",
    "        if global_params['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / global_params['gradient_accumulation_steps']\n",
    "            \n",
    "            \n",
    "            \n",
    "        temp_lossxcal =0\n",
    "\n",
    "        label_4_dcal = labelfloat.clone()\n",
    "        if e>=0:\n",
    "            label_4_dcal  =1.0-label_4_dcal\n",
    "            tgt = cat_bin_target(time2event.clone(), label_4_dcal,global_params['bin_boundaries'], global_params) \n",
    "            xcalloss = compute_xcal(outfull, tgt, global_params)\n",
    "            loss = loss + (global_params['fac']* xcalloss)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        temp_lossxcal += xcalloss.detach().item()\n",
    "\n",
    "        temp_loss += loss.item()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            if BINFLAG:\n",
    "                prec, a, b = precision(logits, labelfloat)\n",
    "            else:\n",
    "                prec = -1\n",
    "            print(\"epoch: {}\\t| Cnt: {}\\t| Loss: {:.5f}\\t| Dcal fac: {:.5f}\\t| Dcal loss: {:.5f}\".format(e, cnt, temp_loss / 100, global_params['fac']  , temp_lossxcal))\n",
    "            temp_loss = 0\n",
    "            temp_lossxcal = 0\n",
    "        if (step + 1) % global_params['gradient_accumulation_steps'] == 0:\n",
    "            optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        tempfac = global_params['fac']\n",
    "        global_params['fac']  =tempfac +scale2add\n",
    "        global_params['fac']  =np.minimum(global_params['fac'],global_params['maxfac'])\n",
    "    # Save a trained model\n",
    "    del dl_train\n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "def evaluationloop(binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "        dataset_test = SODENXcal_DataLoader(BertVocab['token2idx'], test, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "    else:\n",
    "        dataset_test = SODENXcal_DataLoader(BertVocab['token2idx'], test, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "\n",
    "    dl_test = DataLoader(dataset_test, global_params['batch_size'], shuffle=False , collate_fn = collate_fn)\n",
    "\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "    model.binary=binaryFlag\n",
    "    y_time = []\n",
    "    \n",
    "    for step, batch in enumerate(dl_test):\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits , outfull,loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label,labelfloat, time2event, False)\n",
    "\n",
    "            \n",
    "        tgt = cat_bin_target(time2event, labelfloat,global_params['bin_boundaries'],global_params) \n",
    "        xcalloss = compute_xcal(outfull, tgt,global_params)    \n",
    "            \n",
    "        \n",
    "        logits = logits.cpu()\n",
    "        label = label.cpu()\n",
    "        labelfloat = labelfloat.cpu()\n",
    "        time2event = time2event.cpu()\n",
    "        if step % 50 == 0:\n",
    "            print(step)\n",
    "        y_label.append(labelfloat)\n",
    "        y.append(logits)\n",
    "        y_time.append(time2event)\n",
    "        loss_temp = loss_temp+loss.item() \n",
    "\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    y_time = torch.cat(y_time, dim=0)\n",
    "    \n",
    "    if BINFLAG:\n",
    "        tempprc, output, label = precision_test(y, y_label)\n",
    "\n",
    "        tempauroc, output, label = roc_auc(y, y_label)\n",
    "\n",
    "    else:\n",
    "        tempprc, output, label = precision_test(y, y_label)\n",
    "\n",
    "        tempauroc = cindex(y, y_label, y_time)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return tempprc, tempauroc, loss_temp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validationloop(binaryFlag=False):\n",
    "    if binaryFlag:\n",
    "        print('binary on...')\n",
    "\n",
    "        dataset_test = SODENXcal_DataLoader(BertVocab['token2idx'], valid, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "    else:\n",
    "        dataset_test = SODENXcal_DataLoader(BertVocab['token2idx'], valid, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "\n",
    "    dl_test = DataLoader(dataset_test, global_params['batch_size']*4, shuffle=False , collate_fn = None)\n",
    "\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_label = []\n",
    "    loss_temp = 0\n",
    "    model.binary=binaryFlag\n",
    "    y_time = []\n",
    "    pats=[]\n",
    "    \n",
    "    for step, batch in enumerate(dl_test):\n",
    "        model.eval()\n",
    "\n",
    "        \n",
    "        age_ids, input_ids, posi_ids, segment_ids, attMask, time2event, label, labelfloat = batch\n",
    "\n",
    "        age_ids = age_ids.to(global_params['device'])\n",
    "        input_ids = input_ids.to(global_params['device'])\n",
    "        posi_ids = posi_ids.to(global_params['device'])\n",
    "        segment_ids = segment_ids.to(global_params['device'])\n",
    "        attMask = attMask.to(global_params['device'])\n",
    "        time2event = time2event.to(global_params['device'])\n",
    "        label = label.to(global_params['device'])\n",
    "        labelfloat = labelfloat.to(global_params['device'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits , outfull,loss= model(input_ids, age_ids, segment_ids, posi_ids, attMask, label,labelfloat, time2event, True)\n",
    "\n",
    "        logits = outfull.cpu()\n",
    "        label = label.cpu()\n",
    "        labelfloat = labelfloat.cpu()\n",
    "        time2event = time2event.cpu()\n",
    "        if step % 50 == 0:\n",
    "            print(step)\n",
    "        y_label.append(labelfloat)\n",
    "        y.append(logits)\n",
    "        pats.append(label.squeeze(-1))\n",
    "        y_time.append(time2event)\n",
    "        loss_temp = loss_temp+loss.item()\n",
    "\n",
    "    y_label = torch.cat(y_label, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    y_time = torch.cat(y_time, dim=0)\n",
    "    pats = torch.cat(pats)\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    return y_label, y, y_time,pats\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surv modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BertVocab = {}\n",
    "token2idx = {'MASK': 4,\n",
    "  'CLS': 3,\n",
    "  'SEP': 2,\n",
    "  'UNK': 1,\n",
    "  'PAD': 0,\n",
    "            'disease1':5,\n",
    "             'disease2':6,\n",
    "             'disease3':7,\n",
    "             'disease4':8,\n",
    "             'disease5':9,\n",
    "             'disease6':10,\n",
    "             'medication1':11,\n",
    "             'medication2':12,\n",
    "             'medication3':13,\n",
    "             'medication4':14,\n",
    "             'medication5':15,\n",
    "             'medication6':16,\n",
    "            }\n",
    "idx2token = {}\n",
    "for x in token2idx:\n",
    "    idx2token[token2idx[x]]=x\n",
    "BertVocab['token2idx']= token2idx\n",
    "BertVocab['idx2token']= idx2token\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "YearVocab = {'token2idx': {'PAD': 0,\n",
    "  '1987': 1,\n",
    "  '1988': 2,\n",
    "  '1989': 3,\n",
    "  '1990': 4,\n",
    "  '1991': 5,\n",
    "  '1992': 6,\n",
    "  '1993': 7,\n",
    "  '1994': 8,\n",
    "  '1995': 9,\n",
    "  '1996': 10,\n",
    "  '1997': 11,\n",
    "  '1998': 12,\n",
    "  '1999': 13,\n",
    "  '2000': 14,\n",
    "  '2001': 15,\n",
    "  '2002': 16,\n",
    "  '2003': 17,\n",
    "  '2004': 18,\n",
    "  '2005': 19,\n",
    "  '2006': 20,\n",
    "  '2007': 21,\n",
    "  '2008': 22,\n",
    "  '2009': 23,\n",
    "  '2010': 24,\n",
    "  '2011': 25,\n",
    "  '2012': 26,\n",
    "  '2013': 27,\n",
    "  '2014': 28,\n",
    "  '2015': 29,\n",
    "  'UNK': 30},\n",
    " 'idx2token': {0: 'PAD',\n",
    "  1: '1987',\n",
    "  2: '1988',\n",
    "  3: '1989',\n",
    "  4: '1990',\n",
    "  5: '1991',\n",
    "  6: '1992',\n",
    "  7: '1993',\n",
    "  8: '1994',\n",
    "  9: '1995',\n",
    "  10: '1996',\n",
    "  11: '1997',\n",
    "  12: '1998',\n",
    "  13: '1999',\n",
    "  14: '2000',\n",
    "  15: '2001',\n",
    "  16: '2002',\n",
    "  17: '2003',\n",
    "  18: '2004',\n",
    "  19: '2005',\n",
    "  20: '2006',\n",
    "  21: '2007',\n",
    "  22: '2008',\n",
    "  23: '2009',\n",
    "  24: '2010',\n",
    "  25: '2011',\n",
    "  26: '2012',\n",
    "  27: '2013',\n",
    "  28: '2014',\n",
    "  29: '2015',\n",
    "  30: 'UNK'}}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BINFLAG = False\n",
    "\n",
    "\n",
    "data = pd.read_parquet('forDemoTRisk2.parquet')\n",
    "data['baselineage'] = data.study_entry - data.dob \n",
    "data['baselineage'] = data['baselineage'].apply(lambda x : str(int(x.days/30)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ageVocab, _ = age_vocab(max_age=global_params['max_age'], year=global_params['age_year'],\n",
    "                        symbol=global_params['age_symbol'])\n",
    "\n",
    "create_folder(global_params['output_dir'])\n",
    "model_config = {\n",
    "    'vocab_size': len(BertVocab['token2idx'].keys()),  # number of disease + symbols for word embedding\n",
    "    'hidden_size': 150,  # word embedding and seg embedding hidden size\n",
    "    'seg_vocab_size': 2,  # number of vocab for seg embedding\n",
    "    'age_vocab_size': len(ageVocab.keys()),  # number of vocab for age embedding\n",
    "    'max_position_embedding': global_params['max_len_seq'],  # maximum number of tokens\n",
    "    'hidden_dropout_prob': 0.3,  # dropout rate\n",
    "    'num_hidden_layers': 6,  # number of multi-head attention layers required\n",
    "    'num_attention_heads': 6,  # number of attention heads\n",
    "    'attention_probs_dropout_prob': 0.4,  # multi-head attention dropout rate\n",
    "    'intermediate_size': 108,  # the size of the \"intermediate\" layer in the transformer encoder\n",
    "    'hidden_act': 'gelu',\n",
    "    'initializer_range': 0.02,  # parameter weight initializer range\n",
    "    'num_treatment': global_params['treatments'],\n",
    "    'device': global_params['device'],\n",
    "    'concat_embeddings' : True,\n",
    "    'time_nums': 51,\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = {\n",
    "    'lr':8e-5, \n",
    "    'warmup_proportion': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletrainpat = data.sample(frac=0.8).patid.values\n",
    "sampletestpat = data[~data.patid.isin(sampletrainpat)].sample(frac=0.5).patid.values\n",
    "samplevalidpat = data[~data.patid.isin(list(sampletrainpat) + list(sampletestpat))].patid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(list(samplevalidpat) +list(sampletestpat) +list(sampletrainpat) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check these 2 numbers are equal -->  3000 3000\n"
     ]
    }
   ],
   "source": [
    "cutiter= 0\n",
    "train = data[data.patid.isin(sampletrainpat)].reset_index(drop=True)\n",
    "test = data[data.patid.isin(sampletestpat)].reset_index(drop=True)\n",
    "valid = data[data.patid.isin(samplevalidpat)].reset_index(drop=True)\n",
    "\n",
    "print('check these 2 numbers are equal --> ', len(data), len(list(sampletrainpat) + list(sampletestpat) + list(samplevalidpat)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 300, 300, 3000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(valid), len(train) +  len(test) + len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 300, 300, 3000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(valid), len(train) +  len(test) + len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), set(), set())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.patid.values).intersection(set(test.patid.values)), set(valid.patid.values).intersection(set(test.patid.values)), set(train.patid.values).intersection(set(valid.patid.values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SODENXcal_DataLoader(BertVocab['token2idx'], train, global_params['max_len_seq'], max_age=110, year=False, age_symbol=None, min_visit=5)\n",
    "\n",
    "dl_train = DataLoader(dataset_train, global_params['batch_size']*10, shuffle=True, collate_fn = collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49]\n",
      "bin boundaries [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49.]\n"
     ]
    }
   ],
   "source": [
    "bin_boundaries, mid_points = get_bin_boundaries(train, dl_train)\n",
    "global_params['bin_boundaries'] = bin_boundaries\n",
    "global_params['mid_points'] = mid_points\n",
    "global_params['gamma'] = 10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn on concat - cehrt structure - embeddings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRT_SODENXcal(conf, num_labels=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam_surv(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "\n",
    "\n",
    "scheduler = toptimizer.lr_scheduler.ExponentialLR(optim, 0.95, last_epoch=-1)\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t| Cnt: 1\t| Loss: 0.14820\t| Dcal fac: 2.00000\t| Dcal loss: 0.53910\n",
      "0\n",
      "** ** * Saving best fine - tuned model ** ** * \n",
      "lr:  [8e-05, 8e-05]\n",
      "loss: 6.080976665019989, prc : 0.2852404120826138, auroc : 0.9439839034205232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-e85ed3bc4378>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0me\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m70\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0mfullCounter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrainloop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBINFLAG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0mprc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mauroc\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0mloss_temp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluationloop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBINFLAG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-14-6468f4f5cb27>\u001B[0m in \u001B[0;36mtrainloop\u001B[0;34m(e, binaryFlag)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m         \u001B[0mtemp_lossxcal\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mxcalloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade_diffeq2/lib/python3.8/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    243\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 245\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/well/rahimi/users/gra027/conda/envs/pytorch_upgrade_diffeq2/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    143\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    146\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "bestloss = 100000000000\n",
    "# \n",
    "for e in range(70):\n",
    "    fullCounter = trainloop(e, BINFLAG)\n",
    "\n",
    "    prc, auroc ,loss_temp = evaluationloop(BINFLAG)\n",
    "    fullCounter = fullCounter+1\n",
    "\n",
    "    if loss_temp <= bestloss:\n",
    "        patience=0\n",
    "        # Save a trained model\n",
    "        print(\"** ** * Saving best fine - tuned model ** ** * \")\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        output_model_file = os.path.join(global_params['output_dir'],  'outbinfileTRisk2.bin')\n",
    "        create_folder(global_params['output_dir'])\n",
    "        if global_params['save_model']:\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "\n",
    "        best_pre = prc\n",
    "        bestauroc = auroc\n",
    "        bestloss=loss_temp\n",
    "    else:\n",
    "\n",
    "\n",
    "        if patience >=1 and patience <2:\n",
    "            scheduler.step()\n",
    "            print(\"LR: \", scheduler.get_lr())\n",
    "        elif patience>=2:\n",
    "            print(\"LR: \", scheduler.get_lr())\n",
    "\n",
    "            print('quitting... no gains...')\n",
    "            break\n",
    "        print(patience)\n",
    "        patience = patience + 1\n",
    "#     scheduler.step()\n",
    "    print('lr: ' , scheduler.get_lr())\n",
    "    print('loss: {}, prc : {}, auroc : {}'.format(loss_temp, prc, auroc))\n",
    "print('best ever auauroc: ', best_pre)\n",
    "auprcbest.append(best_pre)\n",
    "aurocbest.append(bestauroc)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# surv validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "aurocbest = []\n",
    "auprcbest = []\n",
    "\n",
    "\n",
    "\n",
    "conf = BertConfig(model_config)\n",
    "\n",
    "model = BEHRT_SODENXcal(conf, num_labels=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullBert = os.path.join(global_params['output_dir'],  'outbinfileTRisk2.bin')\n",
    "\n",
    "pretrained_dict = torch.load(fullBert, map_location='cpu')\n",
    "net_dict = model.state_dict()\n",
    "print(len(net_dict))\n",
    "# # 1. filter out unnecessary keys\n",
    "pretrained_dict2 = {k: v for k, v in pretrained_dict.items() if k in net_dict }\n",
    "# # 2. overwrite entries in the existing state dict\n",
    "net_dict.update(pretrained_dict2) \n",
    "model.load_state_dict(net_dict)\n",
    "\n",
    "model = model.to(global_params['device'])\n",
    "optim = adam_surv(params=list(model.named_parameters()), config=optim_config)\n",
    "model.binary = BINFLAG\n",
    "\n",
    "scheduler = TriStageLRScheduler(optim,  5,5,50, 0.00001,0.000005,-1 )\n",
    "patience = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auprcbest =[]\n",
    "aurocbest = []\n",
    "best_pre = -1\n",
    "patience = 0\n",
    "bestauroc = -1\n",
    "\n",
    "\n",
    "e,ph, t,pats = validationloop(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample save of probabilities etc at timepoint 36\n",
    "np.savez(global_params['output_dir'] +'out_time36output.npz', time=t.flatten().numpy(), event=e.flatten().numpy(), pred=ph.numpy()[:,36],  partial_hazard=ph.numpy(), pats=valid.patid.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffeq2",
   "language": "python",
   "name": "pytorch_upgrade_diffeq2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
